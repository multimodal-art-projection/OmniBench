{
    "leaderboardData": [
      {
          "info": {
              "name": "video_salmonn",
              "size": "-",
              "date": "-",
              "type": "model"
          },
          "image-audio": {
              "speech": 34.11,
              "sound event": 31.7,
              "music": 56.6,
              "overall": 35.64,
              "action and activity": 31.47,
              "story description": 28.26,
              "plot inference": 25.74,
              "object identification and description": 62.56,
              "contextual and environmental questions": 36.88,
              "identity and relationship": 37.5,
              "text and symbols": 20.0,
              "count and quantity": 6.67
          },
          "textual_image": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          },
          "textual_audio": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          },
          "textual_image-audio": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          }
      },
      {
          "info": {
              "name": "AnyGPT",
              "size": "-",
              "date": "-",
              "type": "model"
          },
          "image-audio": {
              "speech": 17.77,
              "sound event": 20.75,
              "music": 13.21,
              "overall": 18.04,
              "action and activity": 19.52,
              "story description": 16.52,
              "plot inference": 14.77,
              "object identification and description": 22.27,
              "contextual and environmental questions": 15.6,
              "identity and relationship": 21.88,
              "text and symbols": 12.0,
              "count and quantity": 33.33
          },
          "textual_image": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          },
          "textual_audio": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          },
          "textual_image-audio": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          }
      },
      {
          "info": {
              "name": "uio2-xxl",
              "size": "-",
              "date": "-",
              "type": "model"
          },
          "image-audio": {
              "speech": 34.24,
              "sound event": 36.98,
              "music": 24.53,
              "overall": 33.98,
              "action and activity": 32.27,
              "story description": 29.13,
              "plot inference": 29.96,
              "object identification and description": 48.82,
              "contextual and environmental questions": 34.75,
              "identity and relationship": 25.0,
              "text and symbols": 8.0,
              "count and quantity": 46.67
          },
          "textual_image": {
              "speech": 31.13,
              "sound event": 38.87,
              "music": 21.7,
              "overall": 32.05,
              "action and activity": 36.65,
              "story description": 28.7,
              "plot inference": 34.18,
              "object identification and description": 28.91,
              "contextual and environmental questions": 35.46,
              "identity and relationship": 21.88,
              "text and symbols": 20.0,
              "count and quantity": 26.67
          },
          "textual_audio": {
              "speech": 37.48,
              "sound event": 48.3,
              "music": 46.23,
              "overall": 40.81,
              "action and activity": 43.82,
              "story description": 38.7,
              "plot inference": 35.44,
              "object identification and description": 51.18,
              "contextual and environmental questions": 42.55,
              "identity and relationship": 21.88,
              "text and symbols": 12.0,
              "count and quantity": 33.33
          },
          "textual_image-audio": {
              "speech": 30.22,
              "sound event": 44.53,
              "music": 36.79,
              "overall": 34.15,
              "action and activity": 42.63,
              "story description": 29.57,
              "plot inference": 32.49,
              "object identification and description": 32.23,
              "contextual and environmental questions": 39.72,
              "identity and relationship": 18.75,
              "text and symbols": 16.0,
              "count and quantity": 26.67
          }
      },
      {
          "info": {
              "name": "uio2-large",
              "size": "-",
              "date": "-",
              "type": "model"
          },
          "image-audio": {
              "speech": 25.94,
              "sound event": 29.06,
              "music": 30.19,
              "overall": 27.06,
              "action and activity": 29.88,
              "story description": 20.87,
              "plot inference": 31.65,
              "object identification and description": 30.81,
              "contextual and environmental questions": 23.4,
              "identity and relationship": 18.75,
              "text and symbols": 24.0,
              "count and quantity": 6.67
          },
          "textual_image": {
              "speech": 28.4,
              "sound event": 32.45,
              "music": 26.42,
              "overall": 29.16,
              "action and activity": 28.29,
              "story description": 30.43,
              "plot inference": 32.91,
              "object identification and description": 29.38,
              "contextual and environmental questions": 29.79,
              "identity and relationship": 15.62,
              "text and symbols": 12.0,
              "count and quantity": 13.33
          },
          "textual_audio": {
              "speech": 32.56,
              "sound event": 33.96,
              "music": 48.11,
              "overall": 34.33,
              "action and activity": 34.26,
              "story description": 31.74,
              "plot inference": 37.13,
              "object identification and description": 33.65,
              "contextual and environmental questions": 39.01,
              "identity and relationship": 15.62,
              "text and symbols": 32.0,
              "count and quantity": 40.0
          },
          "textual_image-audio": {
              "speech": 30.61,
              "sound event": 30.19,
              "music": 33.02,
              "overall": 30.74,
              "action and activity": 31.08,
              "story description": 31.3,
              "plot inference": 37.55,
              "object identification and description": 27.01,
              "contextual and environmental questions": 29.79,
              "identity and relationship": 21.88,
              "text and symbols": 16.0,
              "count and quantity": 13.33
          }
      },
      {
          "info": {
              "name": "all_results.json",
              "size": "-",
              "date": "-",
              "type": "model"
          },
          "image-audio": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          },
          "textual_image": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          },
          "textual_audio": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          },
          "textual_image-audio": {
              "action and activity": "-",
              "story description": "-",
              "plot inference": "-",
              "object identification and description": "-",
              "contextual and environmental questions": "-",
              "identity and relationship": "-",
              "text and symbols": "-",
              "count and quantity": "-",
              "overall": "-",
              "music": "-",
              "speech": "-",
              "sound event": "-"
          }
      },
      {
          "info": {
              "name": "uio2-xl",
              "size": "-",
              "date": "-",
              "type": "model"
          },
          "image-audio": {
              "speech": 39.56,
              "sound event": 36.98,
              "music": 29.25,
              "overall": 38.0,
              "action and activity": 32.27,
              "story description": 33.48,
              "plot inference": 31.65,
              "object identification and description": 63.03,
              "contextual and environmental questions": 34.04,
              "identity and relationship": 34.38,
              "text and symbols": 24.0,
              "count and quantity": 20.0
          },
          "textual_image": {
              "speech": 32.43,
              "sound event": 32.45,
              "music": 30.19,
              "overall": 32.22,
              "action and activity": 33.47,
              "story description": 30.0,
              "plot inference": 31.65,
              "object identification and description": 38.86,
              "contextual and environmental questions": 31.91,
              "identity and relationship": 21.88,
              "text and symbols": 12.0,
              "count and quantity": 20.0
          },
          "textual_audio": {
              "speech": 44.49,
              "sound event": 38.11,
              "music": 46.23,
              "overall": 43.17,
              "action and activity": 35.46,
              "story description": 40.43,
              "plot inference": 36.29,
              "object identification and description": 64.93,
              "contextual and environmental questions": 47.52,
              "identity and relationship": 31.25,
              "text and symbols": 36.0,
              "count and quantity": 13.33
          },
          "textual_image-audio": {
              "speech": 31.26,
              "sound event": 40.0,
              "music": 36.79,
              "overall": 33.8,
              "action and activity": 37.45,
              "story description": 30.43,
              "plot inference": 30.38,
              "object identification and description": 39.81,
              "contextual and environmental questions": 39.01,
              "identity and relationship": 18.75,
              "text and symbols": 12.0,
              "count and quantity": 13.33
          }
      }
  ]
}
